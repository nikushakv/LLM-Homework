{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506fcb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama client initialized.\n",
      "Successfully connected to local model 'phi3:mini'.\n",
      "Embedding model loaded.\n",
      "All indexes and metadata have been loaded successfully.\n",
      "FAISS index contains 18 vectors.\n",
      "Metadata contains information for 18 chunks.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rank_bm25 import BM25Okapi\n",
    "from ollama import Client\n",
    "\n",
    "try:\n",
    "    client = Client()\n",
    "    print(\"Ollama client initialized.\")\n",
    "    client.show('phi3:mini') \n",
    "    print(\"Successfully connected to local model 'phi3:mini'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Ollama client: {e}\")\n",
    "    print(\"Please ensure the Ollama application is running and you have downloaded the model (e.g., 'ollama run phi3:mini').\")\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Embedding model loaded.\")\n",
    "\n",
    "INDEX_DIR = 'indexes'\n",
    "FAISS_INDEX_PATH = os.path.join(INDEX_DIR, 'faiss_index.bin')\n",
    "BM25_INDEX_PATH = os.path.join(INDEX_DIR, 'bm25_index.pkl')\n",
    "METADATA_PATH = os.path.join(INDEX_DIR, 'metadata.pkl')\n",
    "\n",
    "try:\n",
    "    faiss_index = faiss.read_index(FAISS_INDEX_PATH)\n",
    "\n",
    "    with open(BM25_INDEX_PATH, 'rb') as f:\n",
    "        bm25_index = pickle.load(f)\n",
    "\n",
    "    with open(METADATA_PATH, 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    \n",
    "    print(\"All indexes and metadata have been loaded successfully.\")\n",
    "    print(f\"FAISS index contains {faiss_index.ntotal} vectors.\")\n",
    "    print(f\"Metadata contains information for {len(metadata)} chunks.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    print(\"Please make sure you have run the '01_indexing.ipynb' notebook first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe22177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_embedding(query_code, k=1, similarity_threshold=0.9):\n",
    "    query_embedding = embedding_model.encode([query_code])\n",
    "    \n",
    "    distances, indices = faiss_index.search(query_embedding, k)\n",
    "    \n",
    "    top_match_index = indices[0][0]\n",
    "    match_distance = distances[0][0]\n",
    "    \n",
    "    cosine_similarity = 1 - (match_distance**2 / 2)\n",
    "    \n",
    "    is_plagiarized = cosine_similarity > similarity_threshold\n",
    "    \n",
    "    match_info = metadata[top_match_index]\n",
    "    \n",
    "    return {\n",
    "        \"is_plagiarized\": bool(is_plagiarized),\n",
    "        \"confidence_score\": float(cosine_similarity),\n",
    "        \"explanation\": f\"The most similar function found has a similarity score of {float(cosine_similarity):.4f}. \"\n",
    "                       f\"The threshold for plagiarism is {similarity_threshold}.\",\n",
    "        \"most_similar_function\": {\n",
    "            \"file_path\": match_info['file_path'],\n",
    "            \"function_name\": match_info['function_name'],\n",
    "            \"code\": match_info['code']\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_full_corpus_text(directory='data/reference_corpus'):\n",
    "    full_text = \"\"\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    full_text += f\"--- START OF FILE: {file_path} ---\\n\\n\"\n",
    "                    full_text += f.read()\n",
    "                    full_text += f\"\\n\\n--- END OF FILE: {file_path} ---\\n\\n\"\n",
    "    return full_text\n",
    "\n",
    "FULL_CORPUS_TEXT = load_full_corpus_text()\n",
    "\n",
    "def detect_llm(query_code):\n",
    "    prompt = f\"\"\"\n",
    "    You are a Code Plagiarism Detection expert. Your task is to determine if the provided \"Query Code\" is plagiarized from the \"Source Code Corpus\".\n",
    "\n",
    "    Analyze the \"Query Code\" and determine if its core logic, structure, or implementation is substantially derived from any part of the \"Source Code Corpus\".\n",
    "\n",
    "    Respond ONLY with a valid JSON object with three keys:\n",
    "    1. \"is_plagiarized\": a boolean (true or false).\n",
    "    2. \"confidence_score\": a float between 0.0 and 1.0.\n",
    "    3. \"explanation\": a brief justification for your decision.\n",
    "\n",
    "    --- SOURCE CODE CORPUS ---\n",
    "    {FULL_CORPUS_TEXT[:20000]} \n",
    "\n",
    "    --- QUERY CODE ---\n",
    "    {query_code}\n",
    "\n",
    "    --- YOUR JSON RESPONSE ---\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat(\n",
    "            model=\"phi3:mini\",\n",
    "            format=\"json\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return json.loads(response['message']['content'])\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e0037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_rag(query_code, k=5):\n",
    "    query_embedding = embedding_model.encode([query_code])\n",
    "    _, indices = faiss_index.search(query_embedding, k)\n",
    "    \n",
    "    retrieved_chunks = [metadata[i] for i in indices[0]]\n",
    "    \n",
    "    context = \"\"\n",
    "    for i, chunk in enumerate(retrieved_chunks):\n",
    "        context += f\"--- Retrieved Function #{i+1} from {chunk['file_path']} ---\\n\"\n",
    "        context += f\"Function Name: {chunk['function_name']}\\n\"\n",
    "        context += f\"Code:\\n{chunk['code']}\\n\\n\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a Code Plagiarism Detection expert. Your task is to determine if the \"Query Code\" is plagiarized from any of the \"Retrieved Functions\" provided as context.\n",
    "\n",
    "    Analyze the \"Query Code\" and determine if its core logic is substantially derived from any of the \"Retrieved Functions\".\n",
    "\n",
    "    Respond ONLY with a valid JSON object with three keys:\n",
    "    1. \"is_plagiarized\": a boolean (true or false).\n",
    "    2. \"confidence_score\": a float between 0.0 and 1.0.\n",
    "    3. \"explanation\": a brief justification. If plagiarized, mention which function it is similar to.\n",
    "\n",
    "    --- RETRIEVED FUNCTIONS (CONTEXT) ---\n",
    "    {context}\n",
    "\n",
    "    --- QUERY CODE ---\n",
    "    {query_code}\n",
    "\n",
    "    --- YOUR JSON RESPONSE ---\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat(\n",
    "            model=\"phi3:mini\",\n",
    "            format=\"json\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return json.loads(response['message']['content'])\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3f1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_hybrid_rag(query_code, k=5):\n",
    "    query_embedding = embedding_model.encode([query_code])\n",
    "    _, dense_indices = faiss_index.search(query_embedding, k)\n",
    "    \n",
    "    tokenized_query = query_code.split()\n",
    "    bm25_scores = bm25_index.get_scores(tokenized_query)\n",
    "    lexical_indices = np.argsort(bm25_scores)[::-1][:k]\n",
    "    \n",
    "    combined_indices = np.union1d(dense_indices[0], lexical_indices)\n",
    "    \n",
    "    retrieved_chunks = [metadata[i] for i in combined_indices]\n",
    "    \n",
    "    context = \"\"\n",
    "    for i, chunk in enumerate(retrieved_chunks):\n",
    "        context += f\"--- Retrieved Function #{i+1} from {chunk['file_path']} ---\\n\"\n",
    "        context += f\"Function Name: {chunk['function_name']}\\n\"\n",
    "        context += f\"Code:\\n{chunk['code']}\\n\\n\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a Code Plagiarism Detection expert. Your task is to determine if the \"Query Code\" is plagiarized from any of the \"Retrieved Functions\" provided as context.\n",
    "\n",
    "    Analyze the \"Query Code\" and determine if its core logic is substantially derived from any of the \"Retrieved Functions\".\n",
    "\n",
    "    Respond ONLY with a valid JSON object with three keys:\n",
    "    1. \"is_plagiarized\": a boolean (true or false).\n",
    "    2. \"confidence_score\": a float between 0.0 and 1.0.\n",
    "    3. \"explanation\": a brief justification. If plagiarized, mention which function it is similar to.\n",
    "\n",
    "    --- RETRIEVED FUNCTIONS (CONTEXT) ---\n",
    "    {context}\n",
    "\n",
    "    --- QUERY CODE ---\n",
    "    {query_code}\n",
    "\n",
    "    --- YOUR JSON RESPONSE ---\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat(\n",
    "            model=\"phi3:mini\",\n",
    "            format=\"json\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return json.loads(response['message']['content'])\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed10a135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Plagiarism Checks on Sample Code ---\n",
      "\n",
      "[1] Pure Embedding Search:\n",
      "{\n",
      "  \"is_plagiarized\": false,\n",
      "  \"confidence_score\": 0.5355204343795776,\n",
      "  \"explanation\": \"The most similar function found has a similarity score of 0.5355. The threshold for plagiarism is 0.9.\",\n",
      "  \"most_similar_function\": {\n",
      "    \"file_path\": \"data\\\\reference_corpus\\\\repo5\\\\14.py\",\n",
      "    \"function_name\": \"bubblesort\",\n",
      "    \"code\": \"def bubblesort(arr):\\n    arr = arr.copy()\\n    n = len(arr)\\n    for i in range(n):\\n        swapped = False\\n        for j in range(0, n - i - 1):\\n            if arr[j] > arr[j + 1]:\\n                arr[j], arr[j + 1] = (arr[j + 1], arr[j])\\n                swapped = True\\n        if not swapped:\\n            break\\n    return arr\"\n",
      "  }\n",
      "}\n",
      "\n",
      "[3] Standard RAG:\n",
      "{\n",
      "  \"is_plagiarized\": true,\n",
      "  \"confidence_score\": 0.95,\n",
      "  \"explanation\": \"The Query Code 'bubblesort' function has a very similar structure and logic to the first retrieved function (Retrieved Function #1), with only minor differences in naming conventions.\"\n",
      "}\n",
      "\n",
      "[4] Hybrid RAG:\n",
      "{\n",
      "  \"is_plagiarized\": false,\n",
      "  \"confidence_score\": 0.0,\n",
      "  \"explanation\": \"The 'Query Code' has a different function name and variable names but the core logic of bubble sort is similar to Insertionsort (Retrieved Function #7). However, since it does not copy or closely mimic any specific syntax from provided functions without significant alterations, we can consider this as original code with only conceptual similarity.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "sample_code = \"\"\"\n",
    "def b_sort(numbers):\n",
    "    list_len = len(numbers)\n",
    "    for i in range(list_len):\n",
    "        for j in range(0, list_len - i - 1):\n",
    "            if numbers[j] > numbers[j + 1]:\n",
    "                numbers[j], numbers[j + 1] = numbers[j + 1], numbers[j]\n",
    "    return numbers\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Running Plagiarism Checks on Sample Code ---\")\n",
    "\n",
    "print(\"\\n[1] Pure Embedding Search:\")\n",
    "result_embedding = detect_embedding(sample_code)\n",
    "print(json.dumps(result_embedding, indent=2))\n",
    "\n",
    "print(\"\\n[3] Standard RAG:\")\n",
    "result_rag = detect_rag(sample_code)\n",
    "print(json.dumps(result_rag, indent=2))\n",
    "\n",
    "print(\"\\n[4] Hybrid RAG:\")\n",
    "result_hybrid = detect_hybrid_rag(sample_code)\n",
    "print(json.dumps(result_hybrid, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
